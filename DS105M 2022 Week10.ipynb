{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c4c08e5-a5a3-485a-b125-115acb999600",
   "metadata": {},
   "source": [
    "**LSE Data Science Institute | DS105M 2022 Week10**\n",
    "\n",
    "**Topic:** Unstructured Data\n",
    "\n",
    "**Author:** [@jonjoncardoso](github.com/jonjoncardoso)\n",
    "\n",
    "**Date:** 29 November 2022\n",
    "\n",
    "---\n",
    "\n",
    "Obs: If you did not attend the lecture, you might notice a few gaps in your understanding when following this notebook. Watch the lecture recording."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e8f867-af1c-4e9d-bab1-4f15ea2796ce",
   "metadata": {},
   "source": [
    "# Why care about unstructured data?\n",
    "\n",
    "Most datasets do not come in a tidy format that can fit perfectly well in a data frame (a structured data format). That is the case, for example, of **text data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9037a0-b4d4-4a73-9ef7-e982feae9703",
   "metadata": {},
   "source": [
    "# Working with Twitter Data\n",
    "\n",
    "We will use [tweepy](https://docs.tweepy.org/en/stable/getting_started.html) library to access Twiter API.\n",
    "\n",
    "The first thing we have to do is authenticate:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb26836-579f-4798-9eeb-515179e5e6af",
   "metadata": {},
   "source": [
    "## üö®üö®üö®üö®KEEP SECRETS OUT! üö®üö®üö®üö®\n",
    "\n",
    "EXTREMELY EXTREMELY IMPORTANT ADVICE:\n",
    "\n",
    "- Don't use your SSH keys ANYWHERE in this notebook. Also, don't put them on Github either!!!\n",
    "- Instead, create a `config.py` file somewhere outside this project (or .gitignore this file). See for example [this Stackoverflow link](https://stackoverflow.com/a/25501861/843365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8412233d-50ba-434c-afa7-461b4d28e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config # This loads the content of the config.py file. If this throws an error, it is because you haven't created a config.py!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8baece2-ad66-456c-8675-312f4b976fc9",
   "metadata": {},
   "source": [
    "## Establish a connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0bffc5a-ae92-47ad-acbd-09077b91bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "client = tweepy.Client(bearer_token=config.bearer_token, \n",
    "                       consumer_key=config.api_key, \n",
    "                       consumer_secret=config.api_key_secret, \n",
    "                       access_token=config.access_token, \n",
    "                       access_token_secret=config.access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807925f-9e7e-4d18-82a0-7eb38fb1df43",
   "metadata": {},
   "source": [
    "## Obtain a few tweets just to test this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8de7c835-4a34-4f76-ac6d-4a544526f7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(data=[<Tweet id=1597581927909060608 text='RT @VTVcanal8: #Qatar2022‚öΩ| Aqu√≠ te mostramos los resultados del Mundial de F√∫tbol Qatar 2022, correspondientes a la jornada de este #28Nov‚Ä¶'>, <Tweet id=1597581927648731137 text='RT @DrBrunoGino: Ver o Eduardo Bolsonaro no Qatar hoje me lembrou que existem m√©dicos PILANTRAS que deveriam estar de plant√£o em UPA do SUS‚Ä¶'>, <Tweet id=1597581926357159937 text='RT @VTVcanal8: #Qatar2022‚öΩ| Estos son los encuentros de la tercera jornada de la Copa Mundial de la FIFA Qatar 2022.\\n\\nAqu√≠ las selecciones‚Ä¶'>, <Tweet id=1597581925157601282 text='netherlands-vs-qatar\\nhttps://t.co/3egyyUiCcI\\nhttps://t.co/3egyyUiCcI https://t.co/HqTgIye952'>, <Tweet id=1597581924880769028 text='Yyyyy... fue a pasear con tini es normal que haya recorrido todo qatar buscando shoppings de m√°rmol https://t.co/9hrmtO4wEN'>, <Tweet id=1597581924247404544 text='@idextratime @bukalapak Belanda 4-0 Qatar #BukaAjaBukalapak'>, <Tweet id=1597581923995779072 text='@chollosdelsuper ü¶Å ¬°Participa en el Mundial de la Naturaleza! üå¥ Vota a tu campe√≥n y gana:\\n‚öΩ Cheques Amazon\\n‚öΩ Pack del Mundial: Camiseta de tu selecci√≥n + AirPods Pro 2¬™ gen + Bal√≥n Qatar 2022\\nüëâhttps://t.co/cVyaBklmq8üëà'>, <Tweet id=1597581923257552897 text='ŸÖÿ®ÿßÿ±ÿßÿ© ŸÇÿ∑ÿ± ŸàŸáŸàŸÑŸÜÿØÿß ÿßŸÑŸäŸàŸÖ ÿ®ÿ´ ŸÖÿ®ÿßÿ¥ÿ± ÿßÿÆÿ®ÿßÿ± ŸÖÿ®ÿßÿ±Ÿäÿßÿ™ ŸÉÿ£ÿ≥ ÿßŸÑÿπÿßŸÑŸÖ FIFA World Cup 2022 ÿ¨ŸÖŸäÿπ ŸÖÿ®ÿßÿ±Ÿäÿßÿ™ ŸÉÿ£ÿ≥ ÿßŸÑÿπÿßŸÑŸÖ ÿßŸÑŸÇÿßÿØŸÖÿ© ÿßŸÑŸäŸàŸÖ ŸÖÿ®ÿßÿ¥ÿ±  ÿ®Ÿä ÿßŸÜ ÿ≥ÿ®Ÿàÿ±ÿ™ ÿßŸÑŸÖŸÅÿ™Ÿàÿ≠ÿ© ŸÉÿ£ÿ≥ ÿßŸÑÿπÿßŸÑŸÖ 2022 ŸÖŸàÿπÿØ FIFA World Cup Qatar 2022‚Ñ¢  https://t.co/a2okPaGNYE'>, <Tweet id=1597581921206341635 text='RT @shafic_osman: A strong case for the World Cup in places like Qatar is how accessible it is for people from Africa. You think this many‚Ä¶'>, <Tweet id=1597581920866832385 text='RT @Javiergg9885: #ULTIMOMINUTO #BrasilNasRuas este pueblo cada d√≠a est√°n m√°s fuertes vamos!! üí™üí™üáßüá∑üáßüá∑ #Brasil #Brazil #Bolsonaro #Bolsonaro‚Ä¶'>], includes={}, errors=[], meta={'newest_id': '1597581927909060608', 'oldest_id': '1597581920866832385', 'result_count': 10, 'next_token': 'b26v89c19zqg8o3fpzhm60iz5w2r7sdojwwvjzepkz3p9'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_tweets = client.search_recent_tweets(query=\"Qatar\")\n",
    "\n",
    "# What is the format of the data returned?\n",
    "public_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a303a993-ed59-48ce-bf1c-c69ec42fbce5",
   "metadata": {},
   "source": [
    "**What kind of data is returned?**\n",
    "\n",
    "üí° From the [tweepy's Response documentation](https://docs.tweepy.org/en/stable/response.html#tweepy.Response), we read that this object is of a particular data type called [named tuple](https://realpython.com/python-namedtuple/#using-namedtuple-to-write-pythonic-code).  It is kind of a dictionary, there are fields with names that contain data inside them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e153b93-80a2-454a-bbb8-318ed9ff5efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data', 'includes', 'errors', 'meta')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_tweets._fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c76ddb2c-4e9a-4625-a449-2b59b6abf1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Tweet id=1597576494720888837 text='‚ÄúN√£o pode isso e aquilo no Qatar‚Ä¶‚Äù\\nMas eles n√£o contavam q o brasileiro tem um coisa mto apaixonante: a alegria! https://t.co/J1T1b5l2Xg'>,\n",
       " <Tweet id=1597576494628208640 text='Netherlands wins \\nNetherlands 2 - 1 Qatar https://t.co/DUtWhDfIBa'>,\n",
       " <Tweet id=1597576494553133056 text='RT @PMU_Sport: üîÆ Les pr√©dictions de @ReveilAudrey &amp; de @NeauMali pour Pays-Bas // Qatar !\\n\\nü§î Vous √™tes #TeamPaysBas ou #TeamQatar ?\\nüîÉ RT +‚Ä¶'>,\n",
       " <Tweet id=1597576494511173632 text='RT @VTVcanal8: #Qatar2022‚öΩ| Disfruta con nosotros todos los encuentros, an√°lisis, estad√≠sticas, mejores jugadas y mucho m√°s con los mejores‚Ä¶'>,\n",
       " <Tweet id=1597576494112727040 text=\"Vraiment a mes yeux les matchs comme √ßa y a pas + inutile üò≠ On sait tous tr√®s bien que le Qatar va ce faire ouvrir en 2 mais on s'emmerde a faire un match üò≠ https://t.co/QV4xN7cYab\">,\n",
       " <Tweet id=1597576493810475009 text='RT @cfootcameroun: ¬´\\xa0Je n‚Äôai pas de probl√®me avec mon grand fr√®re Ernest Obama, j‚Äôai √©t√© puni par le pr√©sident Eto‚Äôo et le coach Rigobert S‚Ä¶'>,\n",
       " <Tweet id=1597576493429035008 text='RT @TheMancUK: He also showed his support for Ukraine and women in Iran. üè≥Ô∏è\\u200düåà‚ù§Ô∏èüëèhttps://t.co/aAr44M4W9C'>,\n",
       " <Tweet id=1597576493252882432 text='RT @ParikPatelCFA: The USA vs Iran game in Qatar tomorrow will be the first time the US is fighting in the Middle East without looking for‚Ä¶'>,\n",
       " <Tweet id=1597576492833452032 text='RT @Football__Tweet: üö® Mario Ferri, the pitch invader from last night, has announced that he has been released by Qatar without being sanct‚Ä¶'>,\n",
       " <Tweet id=1597576492514410497 text='OM : Longoria aper√ßu au Qatar, que mijote-t-il ? https://t.co/YQj9tTtCRm'>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_tweets.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4745236-0043-4af1-af4c-8a9779d43a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'newest_id': '1597576494720888837',\n",
       " 'oldest_id': '1597576492514410497',\n",
       " 'result_count': 10,\n",
       " 'next_token': 'b26v89c19zqg8o3fpzhm60iol0r4ixtrpxfityowxs1h9'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_tweets.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f1fc92-5432-4283-9a02-243d676d6eab",
   "metadata": {},
   "source": [
    "**Interesting...**\n",
    "\n",
    "ü§î Hmmm so we learn that our query has returned only 10 results and from the documentation, we read that `next_token` is used to paginate. This applies to all APIS: when in doubt, check the documentation!\n",
    "\n",
    "Let's look at the next page then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44941620-d8a1-4729-b991-2843e8fa57b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(data=[<Tweet id=1597576491247624192 text=\"Migrant workers were deceived and died for Qatar's World Cup. Thousands want compensation https://t.co/8hwISaR45a\">, <Tweet id=1597576490723704832 text='RT @binnahar85: Criticising Qatar this way or another is not an issue, it is actually a basic right.\\nThe issue here is hypocrisy. Did u do‚Ä¶'>, <Tweet id=1597576490065219585 text='RT @PMU_Sport: üîÆ Les pr√©dictions de @ReveilAudrey &amp; de @NeauMali pour Pays-Bas // Qatar !\\n\\nü§î Vous √™tes #TeamPaysBas ou #TeamQatar ?\\nüîÉ RT +‚Ä¶'>, <Tweet id=1597576490061033472 text='RT @_mydeszn: I‚Äôm live in Qatar. üá∂üá¶‚ù§Ô∏è‚ú®, and yes I‚Äôm actually a white Nigerian https://t.co/pH5WPgtqqs'>, <Tweet id=1597576488987291648 text='RT @HananyaNaftali: The best joke of the World Cup:\\n\\nQatar wants to lecture Israel on human rights. üòÇ #WorldCup2022 #FIFA https://t.co/3pb4‚Ä¶'>, <Tweet id=1597576487745781760 text='RT @RusEmbIran: Moscow has supported the national team of üáÆüá∑Iran before the decisive ‚öΩÔ∏èfootball match with the United States at the 2022 Wo‚Ä¶'>, <Tweet id=1597576487686836225 text='CdM : Benzema apte √† rejoindre les Bleus au Qatar ? Voici la r√©ponse ! https://t.co/33t4iSDFyW'>, <Tweet id=1597576487162777601 text='#Qatar2022 \\n#Qatar https://t.co/iQuByEP4ld'>, <Tweet id=1597576486542016513 text='RT @VTVcanal8: #Qatar2022‚öΩ| Aqu√≠ te mostramos los resultados del Mundial de F√∫tbol Qatar 2022, correspondientes a la jornada de este #28Nov‚Ä¶'>, <Tweet id=1597576485862268930 text='De meest ontroerende sc√®nes op het WK in Qatar: van dansje voor zieke Finlay (11) tot tranen om overleden vader https://t.co/f03ERoUj1s'>], includes={}, errors=[], meta={'newest_id': '1597576491247624192', 'oldest_id': '1597576485862268930', 'result_count': 10, 'next_token': 'b26v89c19zqg8o3fpzhm60iol0r3gidov4hh073543k3h'})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.search_recent_tweets(query=\"Qatar\", next_token='b26v89c19zqg8o3fpzhm60iol0r4ixtrpxfityowxs1h9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc26345-97c6-46a9-9c22-332fe2c61d3d",
   "metadata": {},
   "source": [
    "## What are people talking about LSE on Twitter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6a21a31-5ee8-4098-81dd-cb9ec2dc4a44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_fields=[\"id\", \"text\", \"attachments\", \"author_id\", \"context_annotations\", \"conversation_id\", \n",
    "              \"created_at\", \"entities\", \"in_reply_to_user_id\", \"lang\", \"public_metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5820b828-bc6f-4726-81a6-8b31693e6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "lse_tweets = client.search_recent_tweets(query=\"London School of Economics\", \n",
    "                                         tweet_fields=tweet_fields,\n",
    "                                         max_results=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b574b9ed-3814-4e03-9f7c-e709a627eca8",
   "metadata": {},
   "source": [
    "**Who tweeted that?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a6d066aa-bf1a-4f5d-9d30-17761fb39918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63684604"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lse_tweets.data[0].author_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9bcdb421-90c6-4aee-9f1d-cc3d88d656db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(data=<User id=63684604 name=Guardian Exec Jobs username=GJ_Exec>, includes={}, errors=[], meta={})"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_user(id=lse_tweets.data[0].author_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b552df2e-cf31-4a6f-8af3-89becc38e81b",
   "metadata": {},
   "source": [
    "# Let's create a `tidy` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e69fb8a-1a16-478b-b925-774a544847a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a7ecb8d5-c62d-4e5b-8f9f-19b4af09d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.DataFrame({field: tweet[field] for field in [\"author_id\", \"text\", \"created_at\", \"lang\"]}, index=[tweet[\"id\"]]) for tweet in lse_tweets.data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "012ae83f-2932-4471-b6fd-6a09b79fbb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1597574950415638528</th>\n",
       "      <td>63684604</td>\n",
       "      <td>Director of International Programmes and Impac...</td>\n",
       "      <td>2022-11-29 12:55:24+00:00</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597574643489312769</th>\n",
       "      <td>236346971</td>\n",
       "      <td>RT @fascinatorfun: ‚ÄúThat amounts to a loss of ...</td>\n",
       "      <td>2022-11-29 12:54:11+00:00</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597573860890931200</th>\n",
       "      <td>442976787</td>\n",
       "      <td>The London School of Economics has estimated t...</td>\n",
       "      <td>2022-11-29 12:51:04+00:00</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597572812923088897</th>\n",
       "      <td>276442577</td>\n",
       "      <td>RT @fascinatorfun: ‚ÄúThat amounts to a loss of ...</td>\n",
       "      <td>2022-11-29 12:46:54+00:00</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597571481667768320</th>\n",
       "      <td>188690239</td>\n",
       "      <td>RT @lag_uk: üì¢We are pleased to award the 2022 ...</td>\n",
       "      <td>2022-11-29 12:41:37+00:00</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597321824215650304</th>\n",
       "      <td>1159888310891945985</td>\n",
       "      <td>@philerator @phlannelphysics @bleasdale_r @The...</td>\n",
       "      <td>2022-11-28 20:09:34+00:00</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597318449336037376</th>\n",
       "      <td>4328654057</td>\n",
       "      <td>[ŒöŒªŒπŒ∫ Œ∫Œ±Œπ Œ¥ŒπŒ±Œ≤Œ¨œÉœÑŒµ œÉœÑŒø Œ†Œ°Œ©Œ§Œü ŒòŒïŒúŒë]ŒîŒµŒØœÑŒµ live: ...</td>\n",
       "      <td>2022-11-28 19:56:09+00:00</td>\n",
       "      <td>el</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597317637117464577</th>\n",
       "      <td>1442770309694754821</td>\n",
       "      <td>Œ£œÑŒ∑ŒΩ ŒµŒ∫Œ¥ŒÆŒªœâœÉŒ∑ œÑŒøœÖ ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œøœç Œ†Œ±œÅŒ±œÑŒ∑œÅŒ∑œÑŒ∑œÅŒØŒøœÖ œÑŒøœÖ...</td>\n",
       "      <td>2022-11-28 19:52:56+00:00</td>\n",
       "      <td>el</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597317226960502784</th>\n",
       "      <td>4328654057</td>\n",
       "      <td>[ŒöŒªŒπŒ∫ Œ∫Œ±Œπ Œ¥ŒπŒ±Œ≤Œ¨œÉœÑŒµ œÉœÑŒø Œ†Œ°Œ©Œ§Œü ŒòŒïŒúŒë]ŒîŒµŒØœÑŒµ live: ...</td>\n",
       "      <td>2022-11-28 19:51:18+00:00</td>\n",
       "      <td>el</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597316899246903297</th>\n",
       "      <td>934448438</td>\n",
       "      <td>ŒúŒ∑œÑœÉŒøœÑŒ¨Œ∫Œ∑œÇ ŒºŒµœÑŒ¨ œÑŒ∑ œÉœÖŒΩŒ¨ŒΩœÑŒ∑œÉŒ∑ ŒºŒµ ŒöŒ¨œÅŒøŒªŒø: ŒúœÄŒøœÅŒµŒØ...</td>\n",
       "      <td>2022-11-28 19:50:00+00:00</td>\n",
       "      <td>el</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               author_id  \\\n",
       "1597574950415638528             63684604   \n",
       "1597574643489312769            236346971   \n",
       "1597573860890931200            442976787   \n",
       "1597572812923088897            276442577   \n",
       "1597571481667768320            188690239   \n",
       "...                                  ...   \n",
       "1597321824215650304  1159888310891945985   \n",
       "1597318449336037376           4328654057   \n",
       "1597317637117464577  1442770309694754821   \n",
       "1597317226960502784           4328654057   \n",
       "1597316899246903297            934448438   \n",
       "\n",
       "                                                                  text  \\\n",
       "1597574950415638528  Director of International Programmes and Impac...   \n",
       "1597574643489312769  RT @fascinatorfun: ‚ÄúThat amounts to a loss of ...   \n",
       "1597573860890931200  The London School of Economics has estimated t...   \n",
       "1597572812923088897  RT @fascinatorfun: ‚ÄúThat amounts to a loss of ...   \n",
       "1597571481667768320  RT @lag_uk: üì¢We are pleased to award the 2022 ...   \n",
       "...                                                                ...   \n",
       "1597321824215650304  @philerator @phlannelphysics @bleasdale_r @The...   \n",
       "1597318449336037376  [ŒöŒªŒπŒ∫ Œ∫Œ±Œπ Œ¥ŒπŒ±Œ≤Œ¨œÉœÑŒµ œÉœÑŒø Œ†Œ°Œ©Œ§Œü ŒòŒïŒúŒë]ŒîŒµŒØœÑŒµ live: ...   \n",
       "1597317637117464577  Œ£œÑŒ∑ŒΩ ŒµŒ∫Œ¥ŒÆŒªœâœÉŒ∑ œÑŒøœÖ ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œøœç Œ†Œ±œÅŒ±œÑŒ∑œÅŒ∑œÑŒ∑œÅŒØŒøœÖ œÑŒøœÖ...   \n",
       "1597317226960502784  [ŒöŒªŒπŒ∫ Œ∫Œ±Œπ Œ¥ŒπŒ±Œ≤Œ¨œÉœÑŒµ œÉœÑŒø Œ†Œ°Œ©Œ§Œü ŒòŒïŒúŒë]ŒîŒµŒØœÑŒµ live: ...   \n",
       "1597316899246903297  ŒúŒ∑œÑœÉŒøœÑŒ¨Œ∫Œ∑œÇ ŒºŒµœÑŒ¨ œÑŒ∑ œÉœÖŒΩŒ¨ŒΩœÑŒ∑œÉŒ∑ ŒºŒµ ŒöŒ¨œÅŒøŒªŒø: ŒúœÄŒøœÅŒµŒØ...   \n",
       "\n",
       "                                   created_at lang  \n",
       "1597574950415638528 2022-11-29 12:55:24+00:00   en  \n",
       "1597574643489312769 2022-11-29 12:54:11+00:00   en  \n",
       "1597573860890931200 2022-11-29 12:51:04+00:00   en  \n",
       "1597572812923088897 2022-11-29 12:46:54+00:00   en  \n",
       "1597571481667768320 2022-11-29 12:41:37+00:00   en  \n",
       "...                                       ...  ...  \n",
       "1597321824215650304 2022-11-28 20:09:34+00:00   en  \n",
       "1597318449336037376 2022-11-28 19:56:09+00:00   el  \n",
       "1597317637117464577 2022-11-28 19:52:56+00:00   el  \n",
       "1597317226960502784 2022-11-28 19:51:18+00:00   el  \n",
       "1597316899246903297 2022-11-28 19:50:00+00:00   el  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a347c969-3fb0-4c8b-9e78-8d7645ed61c0",
   "metadata": {},
   "source": [
    "**Let's add the author_id username!**\n",
    "\n",
    "There is a simpler way to do this, but I want to use this to demonstrate the concept of `merge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "165907ab-3d6f-4ce3-a60f-4c8046396d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"author_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ff82c7c9-6b1a-4ebc-ae9a-a174ec736c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_authors = df[\"author_id\"].unique()\n",
    "#all_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c776cdd-cbd0-410f-9e91-b905ab45df5a",
   "metadata": {},
   "source": [
    "**Use `list comprehension` to obtain author_usernames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6d15587b-d605-49a8-8f60-892a01c88617",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Response(data=<User id=63684604 name=Guardian Exec Jobs username=GJ_Exec>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=236346971 name=Bob Massam #FBPEüî∂üíô username=bmassam>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=442976787 name=Ros Chappell üá∫üá¶StandWithUkraine ‚≠êÔ∏èUK Rejoin üá™üá∫ username=RosChappell>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=276442577 name=12Pat username=StarterPat>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=188690239 name=Sam Halvorsen username=samhalvorsen>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1496957719982579712 name=M P username=mexxez16>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=283549521 name=Matthew Aaron Richmond username=mattyrichy>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=578444253 name=Dominique username=dominiquelevack>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=283604227 name=Andy Vermaut username=AndyVermaut>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=105806085 name=Itzel San Roman Pineda username=itzelsanroman>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=2171907357 name=Chris Gough username=clickoncopy>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=146543890 name=KayBüï∑ username=1_Lovelife>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1024939332686307328 name=Latin American Geographies-UK username=lag_uk>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=303875086 name=Ruth Campbell username=RuthCampbell1>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=947433002795184129 name=Paul Allen #RejoinEU-ASAP username=PaulAllenSK1>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=297915262 name=Peter Howells #RejoinEU #FBPE #FBPPR üá™üá∫ username=Peter__Howells>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=126597444 name=Mrs Trevithick username=MrsTrevithick>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=2912442951 name=canog üá∫üá¶ #StandsWithUkraine aka @canog@mastodon username=canogbiz>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1002515918323404800 name=Chromophilia username=ChromophiliaUK>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=351637790 name=Paul O'Connor üáÆüá™ üá¨üáß üá™üá∫ üá∫üá¶ #GTTO #BLM username=BrixDez>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=282914879 name=Fionna O'Leary, üïØüá™üá∫ username=fascinatorfun>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1282744796935868422 name=MrJPCarter username=MrJPCarter1>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=548521594 name=Œ†ŒøŒªŒØœÑŒ∑œÇ Œ§ŒøœÖ ŒöœåœÉŒºŒøœÖ username=PolitisTkosmou>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1581543998090579968 name=Œ¶Œ±ŒπœÉœÑŒπŒ≤Œ±Œª Conne Œ©Œ¥ŒµŒπŒ≥ŒπœÑŒÆ username=NikosKoudounis1>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1586632345129742336 name=The Madras Tribe ü™∂ username=MadrasTribes>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=121517017 name=maddingcrowd username=maddingcrowd07>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1563454808 name=LSE USAPP blog username=LSEUSAblog>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=300790937 name=AgainstAllWarsüè¥‚Äç‚ò†Ô∏èü™êü¶æ‚òòÔ∏è username=S2t2n>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=2826788653 name=Dame Teacher of South London #RejoinEU #NHS#GTTO username=1to1teachers>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1500412236053061636 name=Sassy username=sassyheren>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=245079791 name=Dave Madden üá™üá∫ username=redmadden>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1597274172148912131 name=SFT 210 username=sft_210>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=750192467652280320 name=@pleaseletmevote username=pleaseletmevote>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=3371856143 name=Tha Noto username=AthaNoto>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=253557119 name=Dana mulina username=mulina_cz>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1144377703426138112 name=Deppy username=Deppy90890092>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1443642054370807815 name=ŒúŒ±œÅŒπŒ¨ŒΩŒΩŒ± Œ¶œÅŒµœÅŒ∑ username=tu265ikJ4G3iLxZ>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=615987418 name=atlas9023 username=atlas9023>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1329483502077825025 name=Gerontompempek@ username=gerontompempek>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=334888674 name=Paula Ph. üêæüêæ username=dacandia13>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1460958716 name=Œöapoios Œëllos üåê username=Kapoiosmpla>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=896382234 name=EFSYN username=EFSYNTAKTON>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1652342700 name=Pasco Nkololo username=Nkololotz>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=104473312 name=Charles Rue username=Charles_Rue>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1588421382412591107 name=Mtz (parodi) username=tanzaniaRt>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1253921902755811335 name=Export Processing Zones Authority username=Tanzania_epza>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=731036953295097856 name=ŒúŒ±ŒΩœâŒªŒøœÄŒøœçŒªŒøœÖ ŒùŒ±œÑŒ±œÉŒ± username=Masprixate>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=327267369 name=Nikos Chatzinikolaou username=NChatzinikolaou>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=956498128907227136 name=Jenny username=Jennifer_chm002>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1484347464161185798 name=E J username=EJ03753321>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=53346239 name=Sigmalive username=Sigmalivecom>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=961223387044442112 name=BG üñ§ username=joBeeGeorgeous>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=846141344535916544 name=GCB username=baby_beemer00>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1097864161021825026 name=Dharmendra singh username=Dharmen69191019>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1359791563170275328 name=circuit laundry bot username=BotCircuit>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=2789390689 name=marhaen but not really username=NadsMarhaen>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1425378621363945483 name=Mariana Ruiz username=Marianarrrrrrz>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=373909732 name=enikos.gr username=enikos_gr>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=191434404 name=Michael Hainsworth username=hainsworthtv>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1495800862400290826 name=SPO_POWER username=SPO_Power>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=2579454504 name=AGomes username=xpgomes3>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1113426385974984705 name=Professor Linda Mulcahy username=LindaMulcahy7>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1527074713 name=Ant1news.gr username=AntennaNews>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=38631911 name=Jonathan Price username=B3CPres>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1541466817633419264 name=TraderHustler username=TraderRembrandt>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=916233147033014272 name=Rodney Leigh Care username=LeighCare>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1550534589210296324 name=Eric Clafton username=Tsarumon1>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=2838358556 name=BITSS username=UCBITSS>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=193680125 name=Stevi - üá∫üá¶ #StandWithUkraine #DetestToryValues username=steviweavi>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=340498991 name=Tina Jane White username=tina_jane>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=19685010 name=Sian Jasper username=SianJasper>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=611754326 name=Sue Austin #GENERALELECTIONNOW #GETPRDONE username=sue21320>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1533822985 name=Ain't too Shabby username=ainttooshabbyuk>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=34919012 name=..... username=turks22>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=798652412626161664 name=Dame Carol Voldermort üá∫üá¶ username=carolvolders>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=774510439824822273 name=Brexit Bin üá™üá∫üá¨üáßüá©üá™üïäüá∫üá¶ #BrexitReality username=BrexitBin>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1498629847324807169 name=Raven__ous username=MelinaPavlakou>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=2200853882 name=TheTOC username=TheTOC_gr>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1074572804 name=newmoney.gr username=newmoneygr>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=2389692329 name=College of Humanities & Social Sciences at Rowan username=RowanCHSS>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=59202489 name=M. Drakomathioulakis username=bageragr>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1468691256171806726 name=sotiris@ username=papanatos_>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1358745630533955586 name=ot.gr username=otgr_official>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1497870550332579845 name=MpoumpouLina username=LinaMpoumpou>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=4103637017 name=mononewsgr username=mononewsgr>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1586184488245141504 name=JScott username=JScottHolt47>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=268283495 name=Œ§Œø Œ†Œ±œÅŒ±œÉŒ∫ŒÆŒΩŒπŒø username=paraskhnio>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1159888310891945985 name=Kevin Alexanderman username=k_alexanderman>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=4328654057 name=presshub.gr username=presshub_gr>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=1442770309694754821 name=gegonota.news username=Gegonota_News>, includes={}, errors=[], meta={}),\n",
       " Response(data=<User id=934448438 name=RP.GR username=RP_GR_2020>, includes={}, errors=[], meta={})]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[client.get_user(id=author_id) for author_id in all_authors]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73741ac9-bafa-45d0-a671-8b677c6b1474",
   "metadata": {},
   "source": [
    "**That took quite some time... How do we check if my code is stuck?**\n",
    "\n",
    "üí°Use a library called tqdm for progress bar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "641728ea-e014-4dec-9d7a-eb0b34472c75",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                                                                                               | 0/91 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "TooManyRequests",
     "evalue": "429 Too Many Requests\nToo Many Requests",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[184], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m author_usernames \u001b[38;5;241m=\u001b[39m [client\u001b[38;5;241m.\u001b[39mget_user(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mauthor_id) \u001b[38;5;28;01mfor\u001b[39;00m author_id \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(all_authors)]\n",
      "Cell \u001b[1;32mIn[184], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m author_usernames \u001b[38;5;241m=\u001b[39m [\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_user\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauthor_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m author_id \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(all_authors)]\n",
      "File \u001b[1;32m~\\Workspace\\lse-ds105-course-notes\\resources\\week10\\venv\\lib\\site-packages\\tweepy\\client.py:2441\u001b[0m, in \u001b[0;36mClient.get_user\u001b[1;34m(self, id, username, user_auth, **params)\u001b[0m\n\u001b[0;32m   2438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID or username is required\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2441\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2442\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpansions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtweet.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_auth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_auth\u001b[49m\n\u001b[0;32m   2445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Workspace\\lse-ds105-course-notes\\resources\\week10\\venv\\lib\\site-packages\\tweepy\\client.py:129\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[1;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_request\u001b[39m(\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m, method, route, params\u001b[38;5;241m=\u001b[39m{}, endpoint_parameters\u001b[38;5;241m=\u001b[39m(), json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m     data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_auth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    126\u001b[0m ):\n\u001b[0;32m    127\u001b[0m     request_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_params(params, endpoint_parameters)\n\u001b[1;32m--> 129\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_auth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_auth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_type \u001b[38;5;129;01mis\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\Workspace\\lse-ds105-course-notes\\resources\\week10\\venv\\lib\\site-packages\\tweepy\\client.py:115\u001b[0m, in \u001b[0;36mBaseClient.request\u001b[1;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(method, route, params, json, user_auth)\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TooManyRequests(response)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TwitterServerError(response)\n",
      "\u001b[1;31mTooManyRequests\u001b[0m: 429 Too Many Requests\nToo Many Requests"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "author_usernames = [client.get_user(id=author_id) for author_id in tqdm.tqdm(all_authors)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95935ff4-8244-4a72-a6b0-4840652d483b",
   "metadata": {},
   "source": [
    "**Ok, but we've done the same thing but we did not save it anywhere**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7b021075-bc24-4d62-879d-6bd48e066c90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'author_usernames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[174], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df_authors \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_authors,\n\u001b[1;32m----> 2\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor_username\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mauthor_usernames\u001b[49m})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'author_usernames' is not defined"
     ]
    }
   ],
   "source": [
    "df_authors = pd.DataFrame({\"author_id\": all_authors,\n",
    "                           \"author_username\": author_usernames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2e5f1cc9-2405-4cbf-ba8e-96b1ae4c47db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_authors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[173], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mmerge(df, \u001b[43mdf_authors\u001b[49m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_authors' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df, df_authors, how=\"left\", on=[\"author_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ddc31-0bee-4428-967e-2b2851ca3e1d",
   "metadata": {},
   "source": [
    "# Extract tokens\n",
    "\n",
    "Tokenisation is the process of segmenting text into words, punctuations marks etc.\n",
    "\n",
    "We are going to use spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b090f97a-6a4a-4303-b7b4-6fe51f116b0d",
   "metadata": {},
   "source": [
    "## Which languages are involved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "01f19cc3-0573-460d-a1f8-e8a821f0cd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en     56\n",
       "el     39\n",
       "und     2\n",
       "de      1\n",
       "in      1\n",
       "es      1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lang\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73a23d-1efb-4653-8a97-5e3d5a39c4f5",
   "metadata": {},
   "source": [
    "Check twitter API Documentation to check the languages: https://developer.twitter.com/en/docs/twitter-for-websites/supported-languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfc01a5-194d-40f4-98d5-7b706b60ba25",
   "metadata": {},
   "source": [
    "## Let's focus on language='en' first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a9bd356d-7524-434d-bf27-05c1c908d900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1597336446532472834</th>\n",
       "      <td>19685010</td>\n",
       "      <td>RT @BrexitBin: In case you missed it ...\\nHere...</td>\n",
       "      <td>2022-11-28 21:07:40+00:00</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     author_id  \\\n",
       "1597336446532472834   19685010   \n",
       "\n",
       "                                                                  text  \\\n",
       "1597336446532472834  RT @BrexitBin: In case you missed it ...\\nHere...   \n",
       "\n",
       "                                   created_at lang  \n",
       "1597336446532472834 2022-11-28 21:07:40+00:00   en  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick one random sample\n",
    "sample = df.query(\"lang == 'en'\").sample(1)\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e2d5570a-24b3-4661-a510-d4d22c6bdf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RT @BrexitBin: In case you missed it ...\\nHere's an excerpt from a report into immigration and wages by the London School of Economics. It s‚Ä¶\""
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_the_text = sample[\"text\"].values[0]\n",
    "just_the_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bcf937-9b77-43a4-bb1d-22658c62a75f",
   "metadata": {},
   "source": [
    "üó£Ô∏è **CLASSROOM DISCUSSION:** What does the following represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5227da55-aea6-4d42-b214-d509916d34e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(just_the_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "11d31f53-70a0-4eae-8779-9b21932a8a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(just_the_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0378af0-2c8a-4ccd-95e2-861f0ba2fadd",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6f8597-7056-42f4-8182-7fd26bd32fa8",
   "metadata": {},
   "source": [
    "**We need to load the language related features from spaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "99ce4698-872d-4637-8589-ae43a367592e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "language_parser = English()\n",
    "\n",
    "tokenized_text = language_parser(just_the_text)\n",
    "type(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b81879-354d-432e-ac23-f93506df43fd",
   "metadata": {},
   "source": [
    "üó£Ô∏è **CLASSROOM DISCUSSION:** What do you think the following represents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a12f5cf0-b00e-4946-8bdd-9d28b99a5435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bdc4aa72-c514-4097-a189-7bdc57885e62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT\n",
      "@BrexitBin\n",
      ":\n",
      "In\n",
      "case\n",
      "you\n",
      "missed\n",
      "it\n",
      "...\n",
      "\n",
      "\n",
      "Here\n",
      "'s\n",
      "an\n",
      "excerpt\n",
      "from\n",
      "a\n",
      "report\n",
      "into\n",
      "immigration\n",
      "and\n",
      "wages\n",
      "by\n",
      "the\n",
      "London\n",
      "School\n",
      "of\n",
      "Economics\n",
      ".\n",
      "It\n",
      "s\n",
      "‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "for token in tokenized_text:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10318026-bea0-4e7a-a2a1-b93b6a750294",
   "metadata": {},
   "source": [
    "**Silly way to count repeated tokens using `list comprehension`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "633ae5ff-a219-4581-989d-e8f7bbbfb027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RT             1\n",
       "report         1\n",
       "s              1\n",
       "It             1\n",
       ".              1\n",
       "Economics      1\n",
       "of             1\n",
       "School         1\n",
       "London         1\n",
       "the            1\n",
       "by             1\n",
       "wages          1\n",
       "and            1\n",
       "immigration    1\n",
       "into           1\n",
       "a              1\n",
       "@BrexitBin     1\n",
       "from           1\n",
       "excerpt        1\n",
       "an             1\n",
       "'s             1\n",
       "Here           1\n",
       "\\n             1\n",
       "...            1\n",
       "it             1\n",
       "missed         1\n",
       "you            1\n",
       "case           1\n",
       "In             1\n",
       ":              1\n",
       "‚Ä¶              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([token for token in tokenized_text]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d33e2-da7d-4845-a20d-eae192a2b8d9",
   "metadata": {},
   "source": [
    "**Let's change everything to lowercase:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0d21f833-9682-40c3-a1dd-b21220d6a879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rt             1\n",
       "report         1\n",
       "s              1\n",
       "it             1\n",
       ".              1\n",
       "economics      1\n",
       "of             1\n",
       "school         1\n",
       "london         1\n",
       "the            1\n",
       "by             1\n",
       "wages          1\n",
       "and            1\n",
       "immigration    1\n",
       "into           1\n",
       "a              1\n",
       "@brexitbin     1\n",
       "from           1\n",
       "excerpt        1\n",
       "an             1\n",
       "'s             1\n",
       "here           1\n",
       "\\n             1\n",
       "...            1\n",
       "it             1\n",
       "missed         1\n",
       "you            1\n",
       "case           1\n",
       "in             1\n",
       ":              1\n",
       "‚Ä¶              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenized_test = language_parser(just_the_text.strip().lower())\n",
    "\n",
    "pd.Series([token for token in new_tokenized_test]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eaee38-a171-4810-a9fd-86673687b419",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "https://spacy.io/usage/linguistic-features#lemmatization\n",
    "\n",
    "There are **pre-trained** fancy NLP models that can detect more interesting things about our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "f1726b43-16c7-4553-8a88-4a6b10fcf887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to download the suitable NLP models https://spacy.io/models/en\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2f94a982-0b23-4def-a629-3d0122450e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c19091d7-acfe-46a1-b24d-7696116a5f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'miss'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fancier_tokenized_text = nlp(just_the_text.strip().lower())\n",
    "\n",
    "fancier_tokenized_text[6].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1da5b8cf-3a25-4dff-9a73-02eb498d2100",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in fancier_tokenized_text ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef47e749-359e-48aa-aa1c-e007f0fdad13",
   "metadata": {},
   "source": [
    "### Remove punctuation & stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a43d4d08-c0fe-45ad-a230-f3b5912f5bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " '@lag_uk',\n",
       " 'üì¢',\n",
       " 'pleased',\n",
       " 'award',\n",
       " '2022',\n",
       " 'latin',\n",
       " 'american',\n",
       " 'geographies',\n",
       " 'research',\n",
       " 'group',\n",
       " 'lagrg',\n",
       " 'undergraduate',\n",
       " 'dissertation',\n",
       " 'prize',\n",
       " 'sophia',\n",
       " '‚Ä¶']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Stop words for the English language\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Removing stop words\n",
    "my_tokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "my_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "fa3bece7-65a6-4b83-be32-db99fa05c4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde80f1c-0965-4cf5-ac7c-e69567bfdbcd",
   "metadata": {},
   "source": [
    "## Putting everything together: automating this process\n",
    "\n",
    "Also, check [this tutorial](https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "2e6f96ec-fd60-4952-be0a-d9f6c5532365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "def clean_text(tweet_text):\n",
    "    simpler_text = tweet_text.strip().lower()\n",
    "    mytokens = nlp(simpler_text)\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd0f662-bc34-48d6-b596-33c0e0ac2c4e",
   "metadata": {},
   "source": [
    "Use pandas `apply` to make your code look cleaner!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "988c8027-c67b-4756-8046-12d67880ff97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1597574950415638528    [director, international, programme, impact, l...\n",
       "1597574643489312769    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597573860890931200    [london, school, economic, estimate, brexit, ‚Äì...\n",
       "1597572812923088897    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597571481667768320    [rt, @lag_uk, üì¢, pleased, award, 2022, latin, ...\n",
       "1597568409012948997    [rt, @lag_uk, üì¢, pleased, award, 2022, latin, ...\n",
       "1597565420646518784    [london, school, economic, estimate, brexit, ....\n",
       "1597561904792502272    [andy, vermaut, share, finance, employee, futu...\n",
       "1597557869943357440    [rt, @lag_uk, üì¢, pleased, award, 2022, latin, ...\n",
       "1597557574110310400    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597557330328985601    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597553972101148673    [üì¢, pleased, award, 2022, latin, american, geo...\n",
       "1597551218796400640    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597550605513682944    [@danihas03237661, @rachelreevesmp, @uklabour,...\n",
       "1597548356855017473    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597546567728529408    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597546345329745920    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597545423350411264    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597544424476618752    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597544001024176128    [loss, 20, pound, value, dollar, 2016, london,...\n",
       "1597532263343742976    [wage, relentless, lifelong, struggle, right, ...\n",
       "1597531803463876609    [london, school, economic, estimate, brexit, ‚Äì...\n",
       "1597529966165508097    [rt, @rowanchss, dr, andrew, gooch, new, resea...\n",
       "1597524397912625152    [rt, @pleaseletmevote, london, school, economi...\n",
       "1597522498220101633    [rt, @pleaseletmevote, london, school, economi...\n",
       "1597521340827078658    [bob, ward, policy, communication, director, l...\n",
       "1597520786000343040    [london, school, economic, estimate, brexit, ‚Äì...\n",
       "1597497463195459585    [rt, @tanzania_epza, y'day, courtesy, visit, c...\n",
       "1597497014316572672    [takeaway, financial, time, article, recent, i...\n",
       "1597495381176336384    [rt, @tanzania_epza, y'day, courtesy, visit, c...\n",
       "1597495357663227904    [y'day, courtesy, visit, consultant, london, s...\n",
       "1597470481761726464    [study, jasmine, 6, year, economics, major, lo...\n",
       "1597454565838057472    [rt, @buildconstdes, marshall, building, renow...\n",
       "1597437800512901120    [early, jaggi, vasudev, founder, isha, foundat...\n",
       "1597423073426558976    [@tedcruz, ted, cruz, job, btw, ted, cruz, wif...\n",
       "1597418836063506432    [geopolitic, push, need, microgrid, power, hea...\n",
       "1597399707558494208    [passfield, hall, london, school, economic, lo...\n",
       "1597361914736422912    [rt, @nokianetwork, geopolitic, push, need, mi...\n",
       "1597360851962322944    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597356506529550338    [rt, @africaatlse, want, build, world, üåç, appl...\n",
       "1597354919530762245    [rt, @paulfscott, big, job, klaxon, professor,...\n",
       "1597346141816823808    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597344712083394560    [gy√∂rgy, leave, hungary, 1947, study, economic...\n",
       "1597338677608607744    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597337787044450304    [session, 4, statistic, war, casualty, online,...\n",
       "1597337566789136384    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597337295216340993    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597336446532472834    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597334819918479360    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597334768810541057    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597334585976979456    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597334464983859200    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597334321420869632    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597327914521227265    [dr, andrew, gooch, new, research, feature, lo...\n",
       "1597323389034602497    [@pelosiproject, exactly, thing, understand, l...\n",
       "1597321824215650304    [@philerator, @phlannelphysic, @bleasdale_r, @...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca7375f-835b-4786-94e3-ec0d0ac0ea76",
   "metadata": {},
   "source": [
    "**There is a fancy tqdm for pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f3772637-eb81-46de-9bd7-576715477f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# from tqdm.auto import tqdm  # for notebooks\n",
    "\n",
    "# Create new `pandas` methods which use `tqdm` progress\n",
    "# (can use tqdm_gui, optional kwargs, etc.)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9f36c706-e03d-4eb9-8b8b-8fdf027cb2a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56/56 [00:00<00:00, 168.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1597574950415638528    [director, international, programme, impact, l...\n",
       "1597574643489312769    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597573860890931200    [london, school, economic, estimate, brexit, ‚Äì...\n",
       "1597572812923088897    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597571481667768320    [rt, @lag_uk, üì¢, pleased, award, 2022, latin, ...\n",
       "1597568409012948997    [rt, @lag_uk, üì¢, pleased, award, 2022, latin, ...\n",
       "1597565420646518784    [london, school, economic, estimate, brexit, ....\n",
       "1597561904792502272    [andy, vermaut, share, finance, employee, futu...\n",
       "1597557869943357440    [rt, @lag_uk, üì¢, pleased, award, 2022, latin, ...\n",
       "1597557574110310400    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597557330328985601    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597553972101148673    [üì¢, pleased, award, 2022, latin, american, geo...\n",
       "1597551218796400640    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597550605513682944    [@danihas03237661, @rachelreevesmp, @uklabour,...\n",
       "1597548356855017473    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597546567728529408    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597546345329745920    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597545423350411264    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597544424476618752    [rt, @fascinatorfun, loss, 20, pound, value, d...\n",
       "1597544001024176128    [loss, 20, pound, value, dollar, 2016, london,...\n",
       "1597532263343742976    [wage, relentless, lifelong, struggle, right, ...\n",
       "1597531803463876609    [london, school, economic, estimate, brexit, ‚Äì...\n",
       "1597529966165508097    [rt, @rowanchss, dr, andrew, gooch, new, resea...\n",
       "1597524397912625152    [rt, @pleaseletmevote, london, school, economi...\n",
       "1597522498220101633    [rt, @pleaseletmevote, london, school, economi...\n",
       "1597521340827078658    [bob, ward, policy, communication, director, l...\n",
       "1597520786000343040    [london, school, economic, estimate, brexit, ‚Äì...\n",
       "1597497463195459585    [rt, @tanzania_epza, y'day, courtesy, visit, c...\n",
       "1597497014316572672    [takeaway, financial, time, article, recent, i...\n",
       "1597495381176336384    [rt, @tanzania_epza, y'day, courtesy, visit, c...\n",
       "1597495357663227904    [y'day, courtesy, visit, consultant, london, s...\n",
       "1597470481761726464    [study, jasmine, 6, year, economics, major, lo...\n",
       "1597454565838057472    [rt, @buildconstdes, marshall, building, renow...\n",
       "1597437800512901120    [early, jaggi, vasudev, founder, isha, foundat...\n",
       "1597423073426558976    [@tedcruz, ted, cruz, job, btw, ted, cruz, wif...\n",
       "1597418836063506432    [geopolitic, push, need, microgrid, power, hea...\n",
       "1597399707558494208    [passfield, hall, london, school, economic, lo...\n",
       "1597361914736422912    [rt, @nokianetwork, geopolitic, push, need, mi...\n",
       "1597360851962322944    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597356506529550338    [rt, @africaatlse, want, build, world, üåç, appl...\n",
       "1597354919530762245    [rt, @paulfscott, big, job, klaxon, professor,...\n",
       "1597346141816823808    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597344712083394560    [gy√∂rgy, leave, hungary, 1947, study, economic...\n",
       "1597338677608607744    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597337787044450304    [session, 4, statistic, war, casualty, online,...\n",
       "1597337566789136384    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597337295216340993    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597336446532472834    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597334819918479360    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597334768810541057    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597334585976979456    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597334464983859200    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597334321420869632    [rt, @brexitbin, case, miss, ..., excerpt, rep...\n",
       "1597327914521227265    [dr, andrew, gooch, new, research, feature, lo...\n",
       "1597323389034602497    [@pelosiproject, exactly, thing, understand, l...\n",
       "1597321824215650304    [@philerator, @phlannelphysic, @bleasdale_r, @...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en[\"text\"].progress_apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855b69ac-c9cf-45fd-ab3d-fed7ca8938f9",
   "metadata": {},
   "source": [
    "# Now what\n",
    "\n",
    "Now that you have cleaned and tokenized everything, you can do the fun stuff:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005394a4-401f-4975-9ae1-2cb855740524",
   "metadata": {},
   "source": [
    "## Bag of Words \n",
    "\n",
    "Use `CountVectorizer` from [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) package to create a bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "c4dfee5e-291b-4edb-b340-8b8aa259c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_vector = CountVectorizer(tokenizer = clean_text, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "de05ac07-0158-4a5c-a0d7-ae96c8584f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<56x377 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 945 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vector.fit_transform(df.query(\"lang == 'en'\")[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "9e11a2ad-4ebc-450f-9871-36b94d2cbd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 377)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vector.fit_transform(df.query(\"lang == 'en'\")[\"text\"]).todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "efdf17ff-3ab0-4a85-945d-7315749b05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bow_vector.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f08f019d-03b7-4107-9708-3024fb83e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bag_words = pd.DataFrame(bow_vector.fit_transform(df.query(\"lang == 'en'\")[\"text\"]).todense(),\n",
    "                            columns=bow_vector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c779c972-d08c-4d15-b29a-156298ead8c9",
   "metadata": {},
   "source": [
    "**What are the most frequent tokens?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "461aed3a-214d-4ac0-b35b-c8f031fd45cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "london      52\n",
       "school      51\n",
       "economic    47\n",
       "‚Ä¶           33\n",
       "rt          33\n",
       "wage        12\n",
       "report      11\n",
       "value       11\n",
       "pound       11\n",
       "miss        11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bag_words.sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec9ad46-5251-4327-b912-b01f79e0d56f",
   "metadata": {},
   "source": [
    "üó£Ô∏è **CLASSROOM DISCUSSION** What would you do with this data now?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374f6f77-dfa3-49f7-8c85-8343585f42b4",
   "metadata": {},
   "source": [
    "### PCA + plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "2b17d054-2493-4b5a-bb49-cc6f7c3319df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly==5.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ea3efb3c-b42e-454f-8201-8e2dd418b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train an algorithm called PCA\n",
    "\n",
    "## Read more about it here https://scikit-learn.org/stable/modules/decomposition.html#pca\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "components = pca.fit_transform(df_bag_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "e4d229f8-d896-461c-94cc-7e9c645d7466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame(components, columns=[f\"PC{i+1}\" for i in range(components.shape[1])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
